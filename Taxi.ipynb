{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Taxi",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Z9IKr1B7w8rc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u2Xf5iuxyk2r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env = gym.make(\"Taxi-v2\")\n",
        "env.render()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G08oejTXyp7p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "action_size = env.action_space.n\n",
        "print(\"Action size \", action_size)\n",
        "\n",
        "state_size = env.observation_space.n\n",
        "print(\"State size \", state_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jyyo1Okjysbq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "qtable = np.zeros((state_size, action_size))\n",
        "print(qtable)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EWJ1-gb_y4NC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "total_episodes = 50000 \n",
        "total_test_episodes = 100 \n",
        "max_steps = 99          \n",
        "learning_rate = 0.7         \n",
        "gamma = 0.618  \n",
        "epsilon = 1.0                 \n",
        "max_epsilon = 1.0             \n",
        "min_epsilon = 0.01           \n",
        "decay_rate = 0.01 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7aFEfLF80RYG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for episode in range(total_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    \n",
        "    for step in range(max_steps):\n",
        "        exp_exp_tradeoff = random.uniform(0,1)\n",
        "        \n",
        "        if exp_exp_tradeoff > epsilon:\n",
        "            action = np.argmax(qtable[state,:])\n",
        "        \n",
        "        else:\n",
        "            action = env.action_space.sample()\n",
        "        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "\n",
        "        qtable[state, action] = qtable[state, action] + learning_rate * (reward + gamma * \n",
        "                                    np.max(qtable[new_state, :]) - qtable[state, action])\n",
        "                \n",
        "        state = new_state\n",
        "        \n",
        "        if done == True: \n",
        "            break\n",
        "    \n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FWfePoCS0aYB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env.reset()\n",
        "rewards = []\n",
        "\n",
        "for episode in range(total_test_episodes):\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "        action = np.argmax(qtable[state,:])\n",
        "        \n",
        "        new_state, reward, done, info = env.step(action)\n",
        "        \n",
        "        total_rewards += reward\n",
        "        \n",
        "        if done:\n",
        "            rewards.append(total_rewards)\n",
        "            break\n",
        "        state = new_state\n",
        "env.close()\n",
        "env.render()\n",
        "print (\"Score over time: \" +  str(sum(rewards)/total_test_episodes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iixlv6p-0f2N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}